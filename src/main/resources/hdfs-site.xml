<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

	<!--指定hdfs的nameservice为ns1，
		需要和core-site.xml中的保持一致 -->
	<!-- 使用federation时，HDFS集群别名。名字可以随便起，多个集群时相互不重复即可 -->
	<property>
		<name>dfs.nameservices</name>
		<value>ns1</value>
	</property>
	
	<!-- ns1下面有两个NameNode，分别是nn1，nn2 -->
	<!-- 指定该集群的namenode的机器 -->
	<property>
		<name>dfs.ha.namenodes.ns1</name>
		<value>nn1,nn2</value>
	</property>
	
	<!-- nn1的RPC通信地址 -->
	<property>
		<name>dfs.namenode.rpc-address.ns1.nn1</name>
		<value>dev160:9000</value>
	</property>
	<!-- nn1的http通信地址 -->
	<property>
		<name>dfs.namenode.http-address.ns1.nn1</name>
		<value>dev160:50070</value>
	</property>
	<!-- nn2的RPC通信地址 -->
	<property>
		<name>dfs.namenode.rpc-address.ns1.nn2</name>
		<value>dev161:9000</value>
	</property>
	<!-- nn2的http通信地址 -->
	<property>
		<name>dfs.namenode.http-address.ns1.nn2</name>
		<value>dev161:50070</value>
	</property>
	
	
	<!-- 指定NameNode的元数据在JournalNode上的存放位置 -->
	<!-- 指定该集群的两个NameNode共享edits文件目录时,使用的JournalNode集群信息-->
	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://dev163:8485;dev164:8485;dev165:8485/ns1</value>
	</property>
	<!-- 指定JournalNode在本地磁盘存放数据的位置 -->
	<property>
		<name>dfs.journalnode.edits.dir</name>
		<value>/opt/modules/hadoop-2.7.3/journal</value>
	</property>
	<!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行
	sshfence:当Active出问题后，standby切换成Active，
	此时，原Active又没有停止服务，这种情况下会被强制杀死进程。
	shell(/bin/true)：NN Active和它的ZKFC一起挂了，没有人通知ZK，ZK长期没有接到通知，
	standby要切换，此时，standby调一个shell（脚本内容），这个脚本返回true则切换成功。
	-->
	<!-- 一旦需要NameNode切换，使用ssh方式进行操作 -->
	<property>
		<name>dfs.ha.fencing.methods</name>
		<value>
			sshfence
			shell(/bin/true)
		</value>
	</property>
	
	
	<!-- 使用sshfence隔离机制时需要ssh免登陆 -->
	<!-- 如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置 -->
	<property>
		<name>dfs.ha.fencing.ssh.private-key-files</name>
		<value>/home/admin/.ssh/id_rsa</value>
	</property>
	
	
	<!-- 配置sshfence隔离机制超时时间 -->
	<!--  connect-timeout连接超时 -->
	<property>
		<name>dfs.ha.fencing.ssh.connect-timeout</name>
		<value>30000</value>
	</property>


	
	<!-- ############################ -->	
	<!-- 开启故障自动转移 -->
	<!-- 指定该集群是否启动自动故障恢复，即当NameNode出故障时，
	是否自动切换到另一台NameNode -->
	<!-- <name>dfs.ha.automatic-failover.enabled</name> -->
	<property>
		<name>dfs.ha.automatic-failover.enabled.ns1</name>
		<value>true</value>
	</property>
	
	<!-- 具体处理自动故障转移的进程 -->
	<!-- 指定该集群出故障时，哪个实现类负责执行故障切换 -->
	<property>
		<name>dfs.client.failover.proxy.provider.ns1</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	
	
	
	<property>  
		<name>dfs.webhdfs.enabled</name>  
		<value>true</value>  
	</property>
	
	
	
</configuration>
